{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = [\"Arial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_data_A= pd.read_excel('TEP_1.xlsx',sheet_name='model_1')\n",
    "#pb_data_A.set_index(\"序号\", inplace = True)\n",
    "#pb_data=np.transpose(peibi_cos_data)\n",
    "pb_data_A.set_axis(['序号','TEP(ul)','NMP(ul)','2-Me(ul)','Temp(℃)','MACl(%)','conc(mmol/1000ul)','NMP ratio(%)','Average efficiency','The highest efficiency'],axis=1)\n",
    "#pb_data_A.set_index(\"序号\", inplace = True)\n",
    "pb_data_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d29752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pb_data_A[['TEP(ul)','NMP(ul)','2-Me(ul)','Temp(℃)','MACl(%)','The highest efficiency']]\n",
    "\n",
    "df.columns = ['TEP (μL)',  'NMP (μL)', '2-Me (μL)',  'Temp (°C)', 'MACl (%)', 'Efficiency (%)']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emukit\n",
    "import GPy\n",
    "from emukit.core import ParameterSpace, ContinuousParameter, DiscreteParameter\n",
    "from emukit.core.initial_designs.random_design import RandomDesign\n",
    "from emukit.core.initial_designs.latin_design import LatinDesign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21037b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEP_min, TEP_max, TEP_step = [500, 651, 10] ## Unit: uL\n",
    "TEP_var = np.arange(TEP_min, TEP_max+TEP_step*0.1, TEP_step)\n",
    "TEP_num = len(TEP_var)\n",
    "\n",
    "NMP_min, NMP_max, NMP_step = [10, 81, 5] ## Unit: uL\n",
    "NMP_var = np.arange(NMP_min, NMP_max+NMP_step*0.1, NMP_step)\n",
    "NMP_num = len(NMP_var)\n",
    "\n",
    "TwoMe_min, TwoMe_max, TwoMe_step = [0, 50, 5] ## Unit: uL\n",
    "TwoMe_var = np.arange(TwoMe_min, TwoMe_max+TwoMe_step*0.1, TwoMe_step) \n",
    "TwoMe_num = len(TwoMe_var)\n",
    "\n",
    "Temp_min, Temp_max, Temp_step = [120, 150, 5] ## Unit: degree C\n",
    "Temp_var = np.arange(Temp_min, Temp_max+Temp_step*0.1, Temp_step)\n",
    "Temp_num = len(Temp_var)\n",
    "\n",
    "MACl_min, MACl_max, MACl_step = [10, 40, 5] # Unit: %\n",
    "MACl_var = np.arange(MACl_min, MACl_max+MACl_step*0.1, MACl_step)\n",
    "MACl_num = len(MACl_var)\n",
    "\n",
    "\n",
    "\n",
    "var_array = [TEP_var, NMP_var, TwoMe_var, Temp_var, MACl_var]\n",
    "x_labels = ['TEP (μL)', \n",
    "            'NMP (μL)', \n",
    "            '2-Me (μL)',  \n",
    "            'Temp (°C)', \n",
    "            'MACl (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b490f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_grid = []\n",
    "for tep in TEP_var:\n",
    "    for nmp in NMP_var:\n",
    "        for twome in TwoMe_var:\n",
    "            for temp in Temp_var:\n",
    "                for macl in MACl_var:\n",
    "                    X_all_grid.append([tep, nmp, twome, temp, macl])\n",
    "X_all_grid = np.array(X_all_grid)\n",
    "X_all_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_normalizer(X, var_array = var_array):\n",
    "    \n",
    "    def max_min_scaler(x, x_max, x_min):\n",
    "        return (x-x_min)/(x_max-x_min)\n",
    "    x_norm = []\n",
    "    for x in (X):\n",
    "           x_norm.append([max_min_scaler(x[i], \n",
    "                         max(var_array[i]), \n",
    "                        min(var_array[i])) for i in range(len(x))])\n",
    "                          #min(var_array[i])) for i in range(len(x))])\n",
    "    return np.array(x_norm)\n",
    "def x_denormalizer(x_norm, var_array = var_array):\n",
    "    \n",
    "    def max_min_rescaler(x, x_max, x_min):\n",
    "        return x*(x_max-x_min)+x_min\n",
    "    x_original = []\n",
    "    for x in (x_norm):\n",
    "           x_original.append([max_min_rescaler(x[i], \n",
    "                              max(var_array[i]), \n",
    "                              #min(var_array[i])) for i in range(len(x))])\n",
    "                               min(var_array[i])) for i in range(len(x))])\n",
    "    return np.array(x_original)\n",
    "\n",
    "\n",
    "def get_closest_array(suggested_x):   \n",
    "    \n",
    "    def get_closest_value(given_value, array_list):\n",
    "        absolute_difference_function = lambda list_value :abs(list_value - given_value)  \n",
    "        closest_value = min(array_list, key=absolute_difference_function)  \n",
    "        return closest_value\n",
    "    \n",
    "    var_list = var_array\n",
    "    modified_array = []\n",
    "    for x in suggested_x:\n",
    "        modified_array.append([get_closest_value(x[i], var_list[i]) for i in range(len(x))])\n",
    "    return np.array(modified_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = ParameterSpace([ContinuousParameter('TEP', 0-1/(TEP_num-1)/2, 1+1/(TEP_num-1)/2),\n",
    "                                  ContinuousParameter('NMP', 0-1/(NMP_num-1)/2, 1+1/(NMP_num-1)/2),\n",
    "                                  ContinuousParameter('TwoMe', 0-1/(TwoMe_num-1)/2, 1+1/(TwoMe_num-1)/2),\n",
    "                                  ContinuousParameter('Temp', 0-1/(Temp_num-1)/2, 1+1/(Temp_num-1)/2),\n",
    "                                  ContinuousParameter('MACl', 0-1/(MACl_num-1)/2, 1+1/(MACl_num-1)/2),\n",
    "                                  \n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPy.models import GPRegression\n",
    "from emukit.model_wrappers import GPyModelWrapper\n",
    "x_exp = x_normalizer(df.iloc[:,0:5].values)\n",
    "#print(x_exp)\n",
    "y_exp = np.transpose(([df.iloc[:,-1].values]))\n",
    "X, Y = [x_exp, y_exp]\n",
    "#print(Y)\n",
    "#print(len(x_exp))\n",
    "input_dim = 5\n",
    "ker = GPy.kern.Matern52(input_dim = input_dim, ARD = True)#\n",
    "ker.lengthscale.constrain_bounded(0.01, 10) \n",
    "ker.variance.constrain_bounded(1e-2, 10000.0) \n",
    "model_gpy = GPRegression(X , -Y, ker)\n",
    "model_gpy.Gaussian_noise.variance =0.5**2\n",
    "model_gpy.Gaussian_noise.variance.fix()\n",
    "model_gpy.randomize()\n",
    "model_gpy.optimize_restarts(num_restarts=20,verbose =False, messages=False)\n",
    "objective_model = GPyModelWrapper(model_gpy)\n",
    "print(objective_model.model.kern.lengthscale)\n",
    "print(objective_model.model.kern.variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_obj =  objective_model.model.predict\n",
    "y_pred, y_uncer = f_obj(X)\n",
    "y_pred = -y_pred[:,-1]\n",
    "y_uncer = np.sqrt(y_uncer[:,-1])\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "from scipy.stats import spearmanr\n",
    "fig, axes = plt.subplots(1, 3, figsize=(5.5*3, 4.5))\n",
    "fs = 20\n",
    "lims1 = (0.2, 1.2)\n",
    "axes[0].scatter(Y[:,-1]/20, y_pred/20, alpha = 0.5, c = 'navy' , edgecolor = 'navy')\n",
    "axes[0].errorbar(Y[:,-1]/20, y_pred/20, yerr = y_uncer/20, ms = 0, \n",
    "                 ls = '', capsize = 2, alpha = 0.6,\n",
    "                 color = 'gray', zorder = 0)\n",
    "axes[0].plot(lims1, lims1, 'k--', alpha=0.75, zorder=0)\n",
    "rmse_value = np.sqrt(mean_squared_error(Y[:,-1], y_pred))\n",
    "mae_value = mean_absolute_error(Y[:,-1], y_pred)\n",
    "spearman_value = spearmanr(Y[:,-1], y_pred)[0]\n",
    "rsquared_value = r2_score(Y[:,-1], y_pred)\n",
    "\n",
    "print('MAE:',np.round(mae_value,4), ' ',\n",
    "      'RMSE:', np.round(rmse_value,4), ' ',\n",
    "      'spearman:', np.round(spearman_value,4), ' ',\n",
    "      'R² score:', np.round(rsquared_value,4))\n",
    "\n",
    "title = 'GPR' + \" (MAE=%.2f\" % mae_value+' (%))'\n",
    "axes[0].set_xlabel('Truth Normalized PCE (a.u.)', fontproperties='Arial', fontsize=24, labelpad=15)\n",
    "axes[0].set_ylabel('Prediction Normalized PCE (a.u.)', fontproperties='Arial', fontsize=24, labelpad=15)\n",
    "axes[0].set_title(title, fontsize = fs,fontproperties='Arial', pad=10)\n",
    "        \n",
    "for i in range(len(axes)):\n",
    "    axes[i].tick_params(direction='in', length=5, width=1, labelsize = fs, grid_alpha = 0.5, pad=10)\n",
    "    axes[i].grid(True, linestyle='-.')\n",
    "plt.subplots_adjust(wspace = 0.4)\n",
    "\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].axis(\"off\")\n",
    "plt.savefig(\"TEP_model1.png\", dpi=600, bbox_inches='tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e20b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.bayesian_optimization.loops import BayesianOptimizationLoop\n",
    "from emukit.bayesian_optimization.acquisitions import ExpectedImprovement, \\\n",
    "                                                      NegativeLowerConfidenceBound, \\\n",
    "                                                      MaxValueEntropySearch, \\\n",
    "                                                      ProbabilityOfImprovement\n",
    "from emukit.core.acquisition import IntegratedHyperParameterAcquisition\n",
    "np.random.seed(10)#to make sure the random results is reproducible \n",
    "bs = 8\n",
    "\n",
    "# ## Expeceted Improvement (EI)\n",
    "#acquisition = ExpectedImprovement(objective_model, jitter=.1)\n",
    "# ## Uppper Confidence Bound (UCB)\n",
    "acquisition = NegativeLowerConfidenceBound(objective_model, beta = 1)\n",
    "# ## Maximum Value Entropy Search (MES)\n",
    "#acquisition = MaxValueEntropySearch(objective_model, parameter_space, grid_size = 10000*4)\n",
    "\n",
    "# Make loop and collect points\n",
    "bayesopt = BayesianOptimizationLoop(model=objective_model, \n",
    "                                   space=parameter_space, \n",
    "                                   acquisition=acquisition,\n",
    "                                   batch_size = bs,\n",
    "                                   )\n",
    "                                   #batchsize may need to be >bs due to duplication\n",
    "\n",
    "print('total condition no.:', len(X))\n",
    "print('total device no.:', len(bayesopt.loop_state.Y))\n",
    "print('maximum Y (PCE [%]): ', -np.min(np.transpose(np.round(bayesopt.loop_state.Y, 1))))\n",
    "\n",
    "\n",
    "f_acq = bayesopt.candidate_point_calculator.acquisition.acquisition.evaluate\n",
    "f_obj = objective_model.model.predict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acq_all_grid = f_acq(x_normalizer(X_all_grid))\n",
    "sort_index = np.argsort(acq_all_grid, axis =0)\n",
    "X_new = []\n",
    "top = 130*10 # top 1% = 1300/129360 You should set it according to your confidence in the model (balance of exploitation and exploration)\n",
    "for i in sort_index[-top:]:\n",
    "        X_new.append(X_all_grid[i][0])\n",
    "X_new=np.array(X_new)\n",
    "bs_index = [np.random.randint(top) for i in np.arange(bs)]\n",
    "X_new = X_new[bs_index]\n",
    "acq_new= f_acq(x_normalizer(X_new))\n",
    "y_new_pred, y_new_uncer = f_obj(x_normalizer(X_new))\n",
    "\n",
    "df_Xnew = pd.DataFrame(X_new, columns = x_labels)\n",
    "df_all = pd.concat([df.iloc[:,0:5], df_Xnew])\n",
    "df_all_ = df_all.drop_duplicates()\n",
    "df_Xnew = df_all_.iloc[len(df):len(df)+bs]\n",
    "df_Xnew = df_Xnew.sort_values(by=list(df.columns[0:5]), ignore_index = True)\n",
    "df_Xnew.index = np.arange(len(df_Xnew))+len(df)\n",
    "print('New X:',len(df_Xnew))\n",
    "df_Xnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_eff = y_exp\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4.5), sharey = False)\n",
    "fs = 20\n",
    "exp_cond = (np.arange(len(y_exp))+1).reshape(-1,1)\n",
    "exp_eff = device_eff.reshape(-1,1)\n",
    "\n",
    "f_obj =  objective_model.model.predict\n",
    "y_pred, y_uncer = f_obj(X)\n",
    "y_pred = -y_pred[:,-1]\n",
    "y_uncer = np.sqrt(y_uncer[:,-1])\n",
    "\n",
    "\n",
    "axes[0].scatter(exp_cond, exp_eff, #facecolor = 'none',\n",
    "            edgecolor = 'navy', s = 20, alpha = 0.6, label = 'experiment')\n",
    "\n",
    "axes[0].plot(exp_cond, np.maximum.accumulate(exp_eff), \n",
    "         marker = 'o', ms = 0, c = 'black')\n",
    "\n",
    "axes[0].scatter(exp_cond, y_pred,\n",
    "                s = 50, facecolors='none', alpha = 0.6, edgecolor = 'gray', label = 'predicted')\n",
    "axes[0].errorbar(exp_cond, y_pred, yerr = y_uncer,  \n",
    "                 ms = 1, ls = '', capsize = 2, alpha = 0.6, \n",
    "                 color = 'gray', zorder = 0)\n",
    "\n",
    "\n",
    "y_pred_new, y_uncer_new = f_obj(x_normalizer(df_Xnew.values))\n",
    "y_pred_new = -y_pred_new[:,-1]\n",
    "y_uncer_new = np.sqrt(y_uncer_new[:,-1])\n",
    "\n",
    "axes[0].scatter(np.arange(len(df_Xnew))+1+len(X), y_pred_new,\n",
    "                s = 50, facecolors='none', alpha = 0.6, edgecolor = 'darkgreen', label = 'suggested')\n",
    "axes[0].errorbar(np.arange(len(df_Xnew))+1+len(X), y_pred_new, yerr = y_uncer_new,  \n",
    "                 ms = 0, ls = '', capsize = 2, alpha = 0.6, \n",
    "                 color = 'darkgreen', zorder = 0)\n",
    "\n",
    "\n",
    "axes[0].set_ylabel('Current Best Efficiency', fontsize = 20)\n",
    "axes[0].set_xlabel('Process Condition', fontsize = 20)\n",
    "\n",
    "axes[0].set_ylim(-1, 30)\n",
    "axes[0].set_xlim(-1, 30)\n",
    "axes[0].set_xticks(np.arange(0,40,5))\n",
    "axes[0].legend(fontsize = fs*0.8)\n",
    "\n",
    "axes[1].axis(\"off\")\n",
    "for ax in axes:\n",
    "    ax.tick_params(direction='in', length=5, width=1, labelsize = fs*.8, grid_alpha = 0.5)\n",
    "    ax.grid(True, linestyle='-.')\n",
    "plt.subplots_adjust(wspace = 0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = RandomDesign(parameter_space)\n",
    "x_sampled = design.get_samples(200)\n",
    "x_columns = df_Xnew.iloc[:,0:5].columns\n",
    "for i in range(input_dim):\n",
    "    for j in range(input_dim-i-1):\n",
    "        \n",
    "## Generate a 2D grid for Contour plot\n",
    "        ind1 = i\n",
    "        ind2 = j+i+1\n",
    "        n_steps =21\n",
    "        x1x2y_pred, x1x2y_uncer =[[],[]]\n",
    "        for x1 in np.linspace(0, 1, n_steps):\n",
    "            for x2 in np.linspace(0, 1, n_steps):\n",
    "                x_temp = np.copy(x_sampled)\n",
    "                x_temp[:,ind1] = x1\n",
    "                x_temp[:,ind2] = x2\n",
    "                y_pred, y_uncer = f_obj(x_temp)\n",
    "                x1_org = x_denormalizer(x_temp)[0,ind1]\n",
    "                x2_org = x_denormalizer(x_temp)[0,ind2]\n",
    "                y_pred = -y_pred\n",
    "                x1x2y_pred.append([x1_org, x2_org, np.max(y_pred), np.mean(y_pred), np.min(y_pred)])\n",
    "                x1x2y_uncer.append([x1_org, x2_org, np.max(np.sqrt(y_uncer)), np.mean(np.sqrt(y_uncer)), np.min(np.sqrt(y_uncer))])\n",
    "                \n",
    "        x1 = np.array(x1x2y_pred, dtype=object)[:,0].reshape(n_steps, n_steps)\n",
    "        x2 = np.array(x1x2y_pred, dtype=object)[:,1].reshape(n_steps, n_steps)\n",
    "        y_pred_max = np.array(x1x2y_pred, dtype=object)[:,2].reshape(n_steps, n_steps)\n",
    "        y_pred_mean = np.array(x1x2y_pred, dtype=object)[:,3].reshape(n_steps, n_steps)\n",
    "        y_pred_min = np.array(x1x2y_pred, dtype=object)[:,4].reshape(n_steps, n_steps)\n",
    "        \n",
    "        y_uncer_max = np.array(x1x2y_uncer, dtype=object)[:,2].reshape(n_steps, n_steps)\n",
    "        y_uncer_mean = np.array(x1x2y_uncer, dtype=object)[:,3].reshape(n_steps, n_steps)\n",
    "        y_uncer_min = np.array(x1x2y_uncer, dtype=object)[:,4].reshape(n_steps, n_steps)\n",
    "\n",
    "        fs = 18\n",
    "        title_pad = 16\n",
    "        \n",
    "## Contour for Prediction Efficiency Mean\n",
    "        fig,axes = plt.subplots(1, 3, figsize=(17, 4), sharey = False, sharex = False)\n",
    "        colorbar_offset = [20, 14, 4]\n",
    "        for ax, c_offset, y in zip(axes, colorbar_offset,\n",
    "                                   [y_pred_max, y_pred_mean, y_pred_min]):#[y_pred_max, y_pred_mean, y_pred_min]\n",
    "            \n",
    "            #c_plt1 = ax.contourf(x1, x2, y,levels = np.arange(0,7,0.2)*0.05+c_offset, cmap='plasma', extend = 'both')\n",
    "            c_plt1 = ax.contourf(x1, x2, y, levels = np.arange(19)*0.5/2+c_offset,\n",
    "                                 cmap='plasma', extend = 'both')\n",
    "\n",
    "            # levels = np.arange(19)*0.5+c_offset\n",
    "            cbar = fig.colorbar(c_plt1, ax= ax)\n",
    "            cbar.ax.tick_params(labelsize=fs*0.8)\n",
    "            ax.scatter(x_denormalizer(X)[:, ind1], \n",
    "                       x_denormalizer(X)[:, ind2], \n",
    "                       s = 40, facecolors='white', alpha = 0.5, edgecolor = 'green')\n",
    "\n",
    "            ax.scatter(df_Xnew.values[:, ind1], \n",
    "                       df_Xnew.values[:, ind2], \n",
    "                       s = 50, facecolors='yellow', alpha = 0.9, edgecolor = 'magenta')\n",
    "            ax.set_xlabel(str(x_columns[ind1]),fontsize =  fs,fontproperties='Arial')\n",
    "            ax.set_ylabel(str(x_columns[ind2]),fontsize =  fs,fontproperties='Arial')\n",
    "\n",
    "            x1_delta = (np.max(x1)-np.min(x1))*0.05\n",
    "            x2_delta = (np.max(x2)-np.min(x2))*0.05\n",
    "            ax.set_xlim(np.min(x1)-x1_delta, np.max(x1)+x1_delta)\n",
    "            ax.set_ylim(np.min(x2)-x2_delta, np.max(x2)+x2_delta)\n",
    "            ax.tick_params(direction='in', length=5, width=1, labelsize = fs*.8)\n",
    "\n",
    "\n",
    "        axes[0].set_title('objective fcn max', pad = title_pad,fontsize =  fs,fontproperties='Arial')\n",
    "        axes[1].set_title('objective fcn mean', pad = title_pad,fontsize =  fs,fontproperties='Arial')\n",
    "        axes[2].set_title('objective fcn min', pad = title_pad,fontsize =  fs,fontproperties='Arial')\n",
    "        plt.subplots_adjust(wspace = 0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012901aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
